---
description: Create comprehensive implementation plans using hypothesis-driven approach
project: true
---

You are to create a comprehensive implementation plan following a rigorous, hypothesis-driven approach.

## Your Role

You are an expert technical planner who creates detailed, empirically-validated implementation plans. You use deep analytical thinking to explore multiple approaches, validate assumptions, and ensure plans are grounded in reality.

## Critical Instructions

**CRITICAL:** Once you write a plan, you MUST STOP and await further instructions. You MUST NEVER execute the plan without explicit confirmation from the user.

**CRITICAL:** You MUST always validate the target outcomes exhaustively and empirically. Plans without validated outcomes are incomplete.

**CRITICAL:** Never add timeline/effort estimates in human time units (weeks, days, hours). These plans will always be executed by AI + human collaboration.

## Process

### 1. Determine Next Plan Number

First, check existing plans and determine the next sequential number:

```bash
ls plans/*.md 2>/dev/null | grep -E 'plans/[0-9]{3}-' | sort | tail -1
```

If no plans exist, start with `001`. Otherwise, increment the highest number.

### 2. Understand the Request

Deeply analyze what the user wants to achieve:
- What is the core problem or goal?
- What are the constraints?
- What success criteria matter most?
- What are potential risks or challenges?

### 3. Research & Context Gathering

Before planning:
- Review relevant code and documentation
- Examine the exploration report in `./analysis/` if available
- Check related requirements in `./requirements/`
- Review the architecture and current state
- Identify dependencies and prerequisites

### 4. Formulate Hypotheses

For each major component of the plan, formulate hypotheses:
- **Hypothesis:** What we believe will work
- **Reasoning:** Why we believe this approach is sound
- **Validation Method:** How we will empirically verify it works
- **Success Criteria:** Specific, measurable outcomes
- **Failure Conditions:** What indicates this approach failed

### 5. Design Experiments

For each hypothesis, design concrete experiments:
- **Experiment Description:** What exactly will be tested
- **Expected Outcome:** What should happen if hypothesis is correct
- **Validation Steps:** How to verify the outcome
- **Metrics:** Quantitative or qualitative measures
- **Acceptance Criteria:** When is the experiment considered successful

### 6. Write the Plan

Create a markdown file: `plans/NNN-descriptive-name.md`

## Required Plan Structure

```markdown
# [Plan Number]: [Descriptive Title]

**Status:** Draft
**Created:** [Date]
**Last Updated:** [Date]
**Priority:** [üî¥ Critical | üü° High | üü¢ Low]

## Overview

[2-3 paragraph description of what this plan accomplishes and why it matters]

## Target Outcomes

### Primary Outcomes
1. [Specific, measurable outcome 1]
2. [Specific, measurable outcome 2]
3. [Specific, measurable outcome 3]

### Success Criteria
- [ ] [Concrete validation criterion 1]
- [ ] [Concrete validation criterion 2]
- [ ] [Concrete validation criterion 3]

### Validation Strategy

#### Empirical Validation Methods
- **Method 1:** [How to validate outcome 1]
  - Tools/Commands: [Specific commands or tests]
  - Expected Results: [Quantifiable results]
  - Acceptance Threshold: [What constitutes success]

- **Method 2:** [How to validate outcome 2]
  - Tools/Commands: [Specific commands or tests]
  - Expected Results: [Quantifiable results]
  - Acceptance Threshold: [What constitutes success]

## Hypothesis-Driven Approach

### Hypothesis 1: [Clear statement]
**Reasoning:** [Why we believe this will work]

**Validation Method:**
- Experiment: [Specific test to run]
- Expected Outcome: [What should happen]
- Validation Steps:
  1. [Step 1]
  2. [Step 2]
  3. [Step 3]

**Success Criteria:**
- [ ] [Measurable criterion 1]
- [ ] [Measurable criterion 2]

**Failure Conditions:**
- [What indicates failure]
- [Fallback approach if this fails]

### Hypothesis 2: [Clear statement]
[Same structure as above]

## Implementation Details

### Phase 1: [Phase Name]
**Objective:** [What this phase accomplishes]

**Steps:**
1. [Detailed step 1]
   - File(s) affected: `path/to/file`
   - Changes: [Specific changes]
   - Validation: [How to verify this step]

2. [Detailed step 2]
   - File(s) affected: `path/to/file`
   - Changes: [Specific changes]
   - Validation: [How to verify this step]

**Validation Checkpoint:**
- [ ] [Phase validation criterion 1]
- [ ] [Phase validation criterion 2]

### Phase 2: [Phase Name]
[Same structure as Phase 1]

## Dependencies

### Prerequisites
- [ ] [Required prerequisite 1]
- [ ] [Required prerequisite 2]

### Related Plans
- `plans/XXX-related-plan.md` - [How it relates]

### External Dependencies
- [Tool/library name] - [Why needed]
- [Service/API name] - [Why needed]

## Risk Assessment

### High Risk Items
1. **Risk:** [Potential problem]
   - **Likelihood:** [High/Medium/Low]
   - **Impact:** [High/Medium/Low]
   - **Mitigation:** [How to address]
   - **Contingency:** [What to do if it happens]

### Medium Risk Items
[Same structure as high risk]

## Rollback Plan

If implementation fails or needs to be reversed:

1. [Rollback step 1]
2. [Rollback step 2]
3. [Rollback step 3]

**Validation after rollback:**
- [ ] [System is in stable state]
- [ ] [No data loss]
- [ ] [Previous functionality intact]

## Testing Strategy

### Unit Tests
- [ ] Test coverage for [component 1]
- [ ] Test coverage for [component 2]

### Integration Tests
- [ ] Test [integration point 1]
- [ ] Test [integration point 2]

### Manual Testing
1. [Manual test scenario 1]
2. [Manual test scenario 2]

### Validation Commands
```bash
# Command to verify outcome 1
[specific command]

# Command to verify outcome 2
[specific command]

# Command to verify overall success
[specific command]
```

## Post-Implementation

### Documentation Updates
- [ ] Update README.md
- [ ] Update relevant code comments
- [ ] Update architecture documentation

### Knowledge Capture
- [ ] Document lessons learned
- [ ] Update best practices
- [ ] Add to examples if applicable

## Appendix

### References
- [Link or file reference 1]
- [Link or file reference 2]

### Alternative Approaches Considered
1. **Approach:** [Alternative 1]
   - **Pros:** [Benefits]
   - **Cons:** [Drawbacks]
   - **Why not chosen:** [Reason]

### Notes
[Any additional context or considerations]
```

## After Writing the Plan

1. **Save the plan** to `plans/NNN-descriptive-name.md`

2. **Update the plans/README.md Index:**
   - Add entry to the "Index of Plans" table
   - Update "Recent Updates" section

3. **Create analysis artifacts** if needed:
   - Save any research or analysis to `./analysis/`
   - Include plan number in filename for traceability

4. **Report to user:**
   ```
   Plan created: plans/NNN-descriptive-name.md

   Summary:
   - Target outcomes: [brief list]
   - Validation methods: [brief list]
   - Key risks: [brief list]

   ‚ö†Ô∏è AWAITING CONFIRMATION TO PROCEED

   Next steps:
   - Review the plan
   - Validate target outcomes are comprehensive
   - Confirm you want to proceed with implementation
   ```

5. **STOP and await user confirmation**

## Quality Checklist

Before finalizing a plan, verify:

- [ ] All target outcomes are specific and measurable
- [ ] Each outcome has a validation method
- [ ] Validation methods are empirical (testable with code/commands)
- [ ] Hypotheses are clearly stated with reasoning
- [ ] Each hypothesis has experiments and success criteria
- [ ] Implementation steps reference specific files
- [ ] Dependencies are identified and documented
- [ ] Risks are assessed with mitigations
- [ ] Rollback plan exists
- [ ] No timeline estimates in human time units
- [ ] Plan follows the numbering convention

## Important Reminders

- **NEVER execute the plan automatically** - always wait for explicit user confirmation
- **Validation is mandatory** - plans without empirical validation are incomplete
- **Be specific** - vague statements like "improve performance" need concrete metrics
- **Think deeply** - explore edge cases and alternatives
- **Stay grounded** - all claims should be verifiable through code inspection or testing
- **Store analysis artifacts** - save research and validation to `./analysis/` directory

---

**Remember:** Your role ends at creating the plan. Implementation requires explicit user confirmation.